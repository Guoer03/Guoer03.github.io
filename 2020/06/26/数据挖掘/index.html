<!DOCTYPE html>
<html lang="java">


<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, user-scalable=no">
  <title>
    数据挖掘 | Guoer03的学习笔记
  </title>
  <meta name="description" content="java后端，人工智能">
  
  <meta name="keywords" content="
  数据挖掘,人工智能
  ">
  
  <meta name="author" content="Arthur Ming">

  <meta http-equiv="Cache-Control" content="no-transform"/>
  <meta http-equiv="Cache-Control" content="no-siteapp">
  <meta name="theme-color" content="#1e2327">
  <link rel="apple-touch-icon" href="https://github.githubassets.com/apple-touch-icon.png">
  <link rel="apple-touch-icon" sizes="180x180" href="https://github.githubassets.com/apple-touch-icon-180x180.png">

  <link rel="icon" type="image/x-icon" href="https://github.githubassets.com/favicon.ico">
  <link rel="stylesheet" href="/css/main.css">
  <link rel="stylesheet"
        href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  

  
<script>
  var _hmt = _hmt || [];
  (function(){var hm = document.createElement("script");
    hm.src = "//hm.baidu.com/hm.js?619384c7a8842a5937347674d96c7276";
    var s = document.getElementsByTagName("script")[0];s.parentNode.insertBefore(hm, s);})();
</script>


  <script src="//cdnjs.cloudflare.com/ajax/libs/vue/1.0.25-csp/vue.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/moment.js/2.11.2/moment.min.js"></script>
<meta name="generator" content="Hexo 4.2.1"></head>

<body id="replica-app">

<nav class="navbar-wrapper">
  <div class="navbar">
    <div class="container clearfix">
      <a href="/" class="navbar-logo"><i class="fa fa-github"></i></a>

      <div class="navbar-search float-left desktop-only">
        <div class="navbar-search-form">
          <label for="gsc-i-id1">This website</label>
          <div id="google-search">
            <gcse:search></gcse:search>
          </div>
        </div>
      </div>

      <ul class="navbar-nav float-left">
        
        <li><a href="/archives">Archives</a></li>
        
        
        <li><a href="/categories">Categories</a></li>
        
        
        <li><a href="/tags">Tags</a></li>
        
        
        <li class="desktop-only"><a href="/atom.xml" target="_blank">RSS</a></li>
        
      </ul>

      <ul class="navbar-nav user-nav float-right desktop-only">
        <li class="user-nav-notification">
          <a><span class="user-nav-unread"></span><i class="fa fa-bell"></i></a>
        </li>
        <li>
          <a><i class="fa fa-plus"></i> <i class="fa fa-caret-down"></i></a>
        </li>
        <li class="user-nav-logo">
          <a><img src="/images/header.jpg"> <i class="fa fa-caret-down"></i></i></a>
        </li>
      </ul>
    </div>
  </div>
</nav>

<div class="main-container">
  <header class="header-wrapper desktop-only">
  <div class="container header-site-detail">
    <ul class="header-toolbar">
      <li class="clearfix">
        <a href="/archives" class="header-toolbar-left"><i
                  class="fa fa-file-text"></i> Posts </a>
        <a href="/archives"
           class="header-toolbar-right"> 5 </a>
      </li>
      <li>
        <a href="/tags" class="header-toolbar-left"><i
                  class="fa fa-tags"></i> Tags </a>
        <a href="/tags"
           class="header-toolbar-right"> 8 </a>
      </li>
      <li>
        <a href="/categories" class="header-toolbar-left"><i
                  class="fa fa-folder-open"></i> Categories </a>
        <a href="/categories"
           class="header-toolbar-right"> 0 </a>
      </li>
    </ul>
    <h2 class="header-title">
      <i class="fa fa-book text-muted"></i>
      <a href="/">Guoer03的学习笔记</a>
      
      
    </h2>
  </div>

  <div class="container">
    <div class="header-tab-wrapper clearfix">
      <span class="header-tab header-tab-selected"><i class="fa fa-thumbs-o-up"></i> Like</span>
      <span class="header-tab"><i class="fa fa-share-alt"></i> Share</span>
      <span class="header-tab"><i class="fa fa-comments-o"></i> Discussion</span>
      <span class="header-tab"><i class="fa fa-bookmark-o"></i> Bookmark </span>
      <span class="header-tab"><i class="fa fa-smile-o"></i> Smile <i class="fa fa-caret-down"></i></span>
    </div>
  </div>
</header>


<div class="post-container container">
  <h3>
    <i class="fa fa-user-o"></i>
    Arthur Ming

    <span class="post-date float-right" title="{{moment(1593168639000).format('MMM DD, YYYY, h:mm:ss A')}}">
      
          <i class="fa fa-pencil-square-o"></i>
      
      {{moment(1593168639000).fromNow()}}
    </span>
  </h3>

  <article class="post-content">
    <h1>数据挖掘</h1>
    <br>  

<h2 id="认识数据"><a href="#认识数据" class="headerlink" title="认识数据"></a>认识数据</h2><p><strong>数据对象：</strong>   </p>
<blockquote>
<p>一个数据对象代表一个实体和联系。又被称为样本，实例，数据点，对象，元组等，数据集由具有相同属性的数据对象构成。   </p>
</blockquote>
<p><strong>属性</strong>：表示一个数据对象的某个特征。  </p>
<hr>
<h3 id="属性类型："><a href="#属性类型：" class="headerlink" title="属性类型："></a>属性类型：</h3><p>1.<strong>标称属性</strong>:类别，状态，编码  </p>
<blockquote>
<p>Hair_color={auburn,black,brown,grey,red,white}    </p>
</blockquote>
<p>2.<strong>二元属性</strong>  </p>
<p>&emsp;<strong><em>对称二元</em></strong>：</p>
<blockquote>
<p>同等重要 gender 男 女  </p>
</blockquote>
<p>&emsp;<strong><em>非对称二元</em></strong>：</p>
<blockquote>
<p>非同等重要 HIV 阴性，阳性 阳性稀少且非常重要  </p>
</blockquote>
<p>3.<strong>序数属性</strong><br>&emsp;Size={small,medium,large}等级 连续值之间的具体大小未知<br>4.<strong>数值属性</strong>   </p>
<p>&emsp;区间标度：定义在同等大小的尺度单位上，没有真正的零点.         </p>
<blockquote>
<p>举例： 温度。0度不代表“没有温度”  </p>
</blockquote>
<p>&emsp;比率标度：长度，技术，货币数量。有真正的零点<br>5.<strong>离散属性</strong><br>&emsp;一个有限的或可数的无限集值。</p>
<blockquote>
<p>年龄，每个人的取值是非常多的。只能取离散型的自然数。如果年龄可以细化到某时某分某秒，也可以说是连续型的。  </p>
</blockquote>
<p>6.<strong>连续属性</strong>：可以取实数。比如身高。<br><img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/5F55BE788A3349038C02C650FF15432A/15915" alt=""></p>
<hr>
<h3 id="度量数据的中心趋势："><a href="#度量数据的中心趋势：" class="headerlink" title="度量数据的中心趋势："></a>度量数据的中心趋势：</h3><ul>
<li>均值(截尾均值-去掉最高和最低值)</li>
<li>中位数（有噪声时，是对中心趋势的更好近似）</li>
<li>众数</li>
<li>中列数=(max-min)/2。  </li>
</ul>
<h3 id="度量数据的离散度："><a href="#度量数据的离散度：" class="headerlink" title="度量数据的离散度："></a>度量数据的离散度：</h3><p><strong>四分位数：</strong></p>
<ol>
<li><strong>Q1</strong> (25th 百分位数percentile), <strong>Q3</strong> (75th百分位数percentile)</li>
<li><strong>IQR = Q3 – Q1</strong></li>
<li>五数概括: min, Q1 , median, Q3 , max<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/F04594C30784404097099090A57C75BD/15968" alt="">  </li>
</ol>
<p><strong><em>离群点: 通常是值高/低于四分位数1.5 x IQR</em></strong>  </p>
<p><strong>Boxplot：</strong>使用盒子表示数据   </p>
<ol>
<li>盒子两端是第1、3四分位数, 即盒子高度为四分位数极差IQR  </li>
<li>盒内的线表示中位数  </li>
<li>胡须: 不超过四分位数1.5 x IQR 的最大/小数据点  </li>
<li>离群点Outliers: 单独绘出满足某个离群点阈条件的离群点<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/FBFF600BD63A44FA9A456E9E3CB5BFFB/15933" alt=""> </li>
</ol>
<h3 id="数据统计的图形显示"><a href="#数据统计的图形显示" class="headerlink" title="数据统计的图形显示:"></a>数据统计的图形显示:</h3><p><strong>正态分布曲线：</strong>  </p>
<ol>
<li>[μ–σ, μ+σ]:含有约<strong>68％</strong>的测量(μ: 均值, σ: 标准差)  </li>
<li>[μ–2σ, μ+2σ]: contains about <strong>95%</strong> of it  </li>
<li>[μ–3σ, μ+3σ]: contains about <strong>99.7%</strong> of it  </li>
</ol>
<p><strong>分位数图：</strong><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/3D91633E45CB4DE19A8A161EFC5B987E/15886" alt=""><br><strong>分位数-分位数图：</strong>  </p>
<blockquote>
<p>对于一个变量，有两个观测集，取自两个不同的部门<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/6BB36946EFA84CC9A8E2AD1BB6683150/15904" alt="">  </p>
</blockquote>
<p><strong>直方图：</strong><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/28B4DF81961346CEAC57CA1C685BCF54/15894" alt="">  </p>
<p><strong>散点图：</strong><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/003C70757ACD4A1D9A600A8FFD0CC96B/15922" alt=""><br>&emsp;提供双变量的数据的第一印象：点的聚集，离群点。</p>
<br>
<br>
<br>
### 相似性度量 ###

<hr>
<p><strong>相似性</strong>：越相似，值越大，介于[0,1]<br><strong>相异性</strong>：越相似，值越小。最小为0，最大值是变化的    </p>
<p><strong>标称属性的邻近度量：</strong></p>
<p><strong>相异性：</strong><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/DB9D9136CA5E4B0DBB773784A9D6F17E/15875" alt="">  </p>
<blockquote>
<p>p:刻画对象的标称属性的个数  m：i和j取值相同状态的属性数。</p>
</blockquote>
<hr>
<p><strong>二元属性的邻近性度量：</strong></p>
<p>&emsp;&emsp;<strong>对称二元相异性：</strong><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/E31A76C3520A439C9FB6B4C9CA6EEBBB/15961" alt="">   </p>
<blockquote>
</blockquote>
<pre><code>q:对象i和对象j都取1的属性数 t:对象i和j都取0的属性数
r:对象i中取1，对象j中取0的属性数 s：对象i中取0，在对象j中取1的属性数  </code></pre><p>&emsp;&emsp;<strong>非对称二元相异性：</strong>  </p>
<p>&emsp;&emsp;&emsp;&emsp;在非对称二元属性中<em>负匹配系数t被认为是不重要的</em>，可忽略：<br>  &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;  <img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/83E51349E24A468DA0C7E9AB310695F3/15960" alt=""><br>&emsp;&emsp;&emsp;&emsp;<strong>相似性：</strong><br>;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/0F7B10A6229E45ADACDDB7BCBAAF9268/15956" alt=""> </p>
<hr>
<p><strong>数值属性的相异性：</strong>   </p>
<p>&emsp;&emsp;&emsp;&emsp;<strong>闵可夫斯基距离：</strong>  </p>
<p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/5585963D0E7849BF986CE7AB95FE8D85/15910" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;当h=1，曼哈坦距离:<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/95F9A0867679456AB23A73BBA2E4D17D/15939" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;当h=2，欧几里得距离：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/594C381964FC4F9287C097DC23D7B05F/15938" alt="">  </p>
<hr>
<p><strong>有序变量的相异性：</strong>  </p>
<blockquote>
<p>把每一个属性均匀地分配到[0，1]<br>   然后用闵可夫斯基距离计算相异度  </p>
</blockquote>
<hr>
<p><strong>混合属性的相异性：</strong><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/108B857BDB664F329F404E795C8D6493/15949" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/1FCC3096ED2E441CA62E0285AB5186E3/15919" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/6500E8B75D6845EFAD84C59407F93BBF/15885" alt=""><br>比如：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/42717B0D693640DBBF26D56E825B9C5E/15947" alt="">  </p>
<hr>
<p><strong>余弦相似性：</strong><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/4E908D69BCFF4BC481B81EFA987F337D/15953" alt=""><br><img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/5C0CE8353F274FC08DDDEFF6DED5C7DB/15877" alt=""><br><br><br><br><br>如果属性是二值属性：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/E3CA436FEC3948389AD5CDB35F9DC09A/15969" alt="">  </p>
<hr>
<hr>
<h2 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h2><p><strong>错误数据处理：</strong>结合数据反映的实际问题，进行分析，更改，删除或忽略<br><strong>处理缺失数据：</strong><br>&emsp;&emsp;&emsp;1.忽略元组。<br>&emsp;&emsp;&emsp;2.手工填写。<br>&emsp;&emsp;&emsp;3.自动填充：用一个全局变量，使用属性均值或中位数（或与目标元组同一类的所有样本的属性均值），使用最可能的值：基于推理的方法。<br><strong>处理噪声数据：</strong></p>
<blockquote>
<p>噪声：是一个测量变量中的随机错误或偏差，包括错误的值或偏离期望值的孤立点</p>
</blockquote>
<p><strong>分箱：</strong>通过考察数据的近邻来光滑有序数据的值。<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/C869A0FB03D24D9BA2DACA1ACDC62E9F/15930" alt=""><br>  等深分箱法：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/53BD42008A5C4669956BDBE14516243C/15944" alt=""><br> 用箱平均值平滑：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/0E385D61C59C401684EC83B2DB9596A7/15940" alt="">  </p>
<p>用箱边界平滑（取最近的边界值）：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/C885B2DEB56A49468AD1A946240E917C/15945" alt=""></p>
<p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/7F83BF7B335E430DADAE91141C368F2C/15913" alt=""><br>等宽分箱法：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/9E229B81D3DC43C683BE95871DF067B7/15909" alt=""><br>用户自定义区间：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/40A31992EBBC4D9D9E1C6BABB033FE75/15901" alt="">  </p>
<p>如果要处理离群点：<br>&emsp;&emsp;&emsp;&emsp;1.<strong>四分位数盒图</strong>，u±3σ范围之外的为离群点<br>&emsp;&emsp;&emsp;&emsp;2.<strong>聚类</strong><br>&emsp;&emsp;&emsp;&emsp;3.<strong>计算机和人工检查结合 **<br>&emsp;&emsp;&emsp;&emsp;4.</strong>回归**：让数据适应回归函数来平滑数据。<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;线性回归（二元关系）<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;多元回归（多变量）  </p>
<h2 id="数据集成："><a href="#数据集成：" class="headerlink" title="数据集成："></a>数据集成：</h2><p>&emsp;&emsp;&emsp;&emsp;<strong>实体识别问题</strong>：匹配来自不同数据源的现实世界的实体<br>&emsp;&emsp;&emsp;&emsp;<strong>数据冗余问题</strong>：一个属性可以由另一个属性或者另一组属性导出<br><strong>标称属性的冗余分析</strong>：如果两个标称属性足够相关，则证明有一个是冗余的<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/0ACB544F8B284134856A9398BB172590/15927" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/6A6D39EEB3C24836AC007BA40146C039/15891" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/6A6D39EEB3C24836AC007BA40146C039/15891" alt=""><br>数值属性的冗余分析：<br>相关系数(皮尔逊相关系数)：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/FDF9639DCF4946F2B9480CF50E76A068/15888" alt=""><br>协方差：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/EF77E232DF544CB48BED8796DE80DD36/15883" alt=""><br><br></p>
<h2 id="数据规约："><a href="#数据规约：" class="headerlink" title="数据规约："></a>数据规约：</h2><blockquote>
<p>得到数据集的归约表示，在归约的数据上进行挖掘，所需的时间和内存资源更少  </p>
</blockquote>
<p>&emsp;&emsp;<strong>维归约：</strong>  </p>
<p>&emsp;&emsp;&emsp;&emsp;<strong>主成分分析PCA</strong>—找到一个投影能表示数据的最大变化，导致维度减少，只对数值数据有效<br>&emsp;&emsp;&emsp;&emsp;<strong>子集选择：</strong>通过删除不相干的属性或维减少数据量<br>&emsp;&emsp;&emsp;&emsp;<strong>向前选择：</strong>从空开始，每次把最好的属性加入到集合中<br>&emsp;&emsp;&emsp;&emsp;<strong>向后选择：</strong>每次删除一个最坏的<br>&emsp;&emsp;&emsp;&emsp;<strong>向前向后结合：</strong>每次选择一个最好的，删除最坏的<br>&emsp;&emsp;&emsp;&emsp;<strong>判定归纳树：</strong>利用信息增益量建立分类判定树  </p>
<p>&emsp;&emsp;<strong>数值归约：</strong><br>&emsp;&emsp;&emsp;&emsp;<strong>有参方法：</strong><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;线性回归<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;多元回归<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;对数线性回归<br>&emsp;&emsp;&emsp;&emsp;<strong>无参方法：</strong><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;直方图<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/62F34E5C3FE74B05AC697F1AC0BC3CA3/15881" alt=""></p>
<p>&emsp;&emsp;<strong>聚类</strong>  </p>
<blockquote>
<p>将数据集划分为聚类，然后通过聚类来表示数据集  </p>
</blockquote>
<p>&emsp;&emsp;<strong>抽样</strong><br>关键原则：选择一个具有代表性的数据子集<br>无放回简单随机抽样：抽中的目标从总体中去除，相同的概率选择任何特定项目<br>放回简单随机抽样：一个被抽中的目标不从总体中去除<br>簇抽样<br>分层抽样<br><br></p>
<h2 id="数据压缩："><a href="#数据压缩：" class="headerlink" title="数据压缩："></a>数据压缩：</h2><p>&emsp;&emsp;无损压缩VS有损压缩<br>&emsp;&emsp;字符串压缩：无损压缩<br>&emsp;&emsp;音频/视频压缩：有损压缩  </p>
<blockquote>
<p>两种有损数据压缩的方法：小波变换和主成分分析<br><br></p>
</blockquote>
<h2 id="数据变换："><a href="#数据变换：" class="headerlink" title="数据变换："></a>数据变换：</h2><blockquote>
<p>采用线性或非线性的数学变换方法，消除数据在时间，空间，属性及精度等特征表现方面的差异<br>规范化：  </p>
</blockquote>
<p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;最小-最大规范化：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/281D489F4BDA4925920E8CB168F450DF/15936" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;Z-score规范化：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/F2F6D8E18C2A4332A541E5076C6ADABD/15958" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;小数定标规范化：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/8970AAFD1A094121AAEDC7AF77A47C8D/15924" alt=""><br><br> </p>
<h2 id="数据离散化："><a href="#数据离散化：" class="headerlink" title="数据离散化："></a>数据离散化：</h2><blockquote>
<p>将数值属性的范围划分为区间  </p>
</blockquote>
<p>&emsp;&emsp;&emsp;&emsp;分箱<br>&emsp;&emsp;&emsp;&emsp;直方图<br>&emsp;&emsp;&emsp;&emsp;聚类<br>&emsp;&emsp;&emsp;&emsp;基于X2分析的区间合并<br>&emsp;&emsp;&emsp;&emsp;基于熵  </p>
<p><strong>概念分层</strong>：通过使用高层的概念来替代底层的属性值来归约数据<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;用户/专家在模式级显式地指定属性的偏序<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;由用户或专家在模式级显式的说明属性的部分序。<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;通过显式数据分组说明分层<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;通过显示数据分组说明分层结构的一部分。<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;只说明属性集：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;说明属性集，但不说明它们的偏序，然后系统根据算法自动产生属性的序，构造有意义的概念分层。（相比低层，高层概念的属性通常有较少取值）<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;只说明部分属性值：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;对只说明部分属性集的情况，则可根据数据库模式中的数据语义定义对属性的捆绑信息，来恢复相关的属性。  </p>
<hr>
<hr>
<h2 id="频繁模式挖掘"><a href="#频繁模式挖掘" class="headerlink" title="频繁模式挖掘"></a>频繁模式挖掘</h2><p><strong>关联规则挖掘</strong>：从大量数据集中发现有趣的，频繁出现的模式，关联和相关性，通过量化的数字描述项集X的出现对项集Y的出现有多大的影响. </p>
<p>   <strong>核心：</strong>关联规则挖掘的核心就是<strong>要找出事务数据库D中的所有强关联规则</strong> </p>
<p>   <strong>事务数据库：</strong>所有事务的集合构成关联规则挖掘的数据集，称为事务数据库。  </p>
<p>   <strong>事务：</strong>因此顾客的一次购物可以用该顾客所购买的所有商品的名称来表示，称为事务。  </p>
<p>   <strong>支持度：</strong>D中<strong>包含A和B的事务数与总的事务数的比值</strong> 为规则A=&gt;B的支持度  </p>
<p>   <strong>置信度：</strong>D中<strong>同时包含A和B的事务数</strong>与<strong>只包含A的事务数</strong>的比值  </p>
<p>   <strong>频繁项集：</strong>若项集X的支持度大于或等于用户指定的<strong>最小支持度</strong>，则项集X称为频繁项集。<br>   如果一个项集是频繁的，他的每个子集也是频繁的。<br><strong>闭的</strong>：</p>
<blockquote>
<p>如果X不存在真超项集Y使得Y与X在D中具有相同的支持度计数    </p>
</blockquote>
<p><strong>闭频繁项集</strong>：  </p>
<blockquote>
<p>如果X在D中是闭的和频繁的，则说项集X是数据集D中的闭频繁项集。  </p>
</blockquote>
<p><strong>极大频繁项集</strong>：  </p>
<blockquote>
<p>如果X是频繁的，并且不存在超项集Y使得    X属于Y并且Y也是频繁的<br><img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/C9BDC422AB54422FB394BB76FC675DBB/15872" alt="">   </p>
</blockquote>
<p>&emsp;&emsp;&emsp;<strong>Apriori性质1:</strong><br>&emsp;&emsp;&emsp;频繁项集的子集必为频繁项集    </p>
<p>&emsp;&emsp;&emsp;<strong>Apriori性质2:</strong>&emsp;&emsp;&emsp;非频繁项集的超集必定是非频繁项集  </p>
<p>&emsp;&emsp;&emsp;<strong>Apriori步骤:</strong><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;1.扫描一次事务集合，找出所有频繁1项集<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;2.基于频繁一项集，自连接+剪枝得到候选2项集，再扫描一次事务集合，得到候选支持度计数，与最小支持度比较，找到频繁2项集。<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;3.以此类推，直到找出最后的频繁项集。最后在所有的频繁项集中产生强关联规则<br>&emsp;&emsp;&emsp;<strong>Apriori例子：</strong>  </p>
<blockquote>
<p>1，2 steps  </p>
</blockquote>
<p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/23B2A203686D4E63BA3651ED37F19E2D/15892" alt="">  </p>
<blockquote>
<p>3 steps    </p>
</blockquote>
<p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/42745D7818064CCC9ADCACDB0FB5AE32/15879" alt=""><br><strong>Apriori的瓶颈：</strong>候选集生成 </p>
<ul>
<li>巨大的候选集  </li>
<li>多次扫描数据库  </li>
<li>繁重的计算候选集的支持度工作   </li>
</ul>
<p>改进：</p>
<ul>
<li>减少事务数据库的扫描次数  </li>
<li>缩减候选项集的数量  </li>
<li>使候选项集的支持度计算计算更加方便  </li>
</ul>
<p><strong>AprioriTid算法</strong>  </p>
<ul>
<li>优点：只和数据库做一次交互，无需频繁访问数据库  </li>
<li>缺点：内存需求很大。<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/31CDC6F5EB894461A6BDB5E7B9249389/15911" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; &emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/F23A28F85F43424D91DA9D590DC8CE34/15926" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; &emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/598CEDBCB2744C318FF9D0B26B2881F6/15931" alt="">  </li>
</ul>
<p><strong>提高Apriori效率的方法</strong>  </p>
<p><strong>事务压缩：</strong>不包含任何频繁k-项集的事务也不可能包含任何大于k的频繁集  </p>
<p><strong>基于划分：</strong>一个项集想要在整个数据库中是频繁的，那么至少要在数据库的一个分割上是频繁的  </p>
<p><strong>采样：</strong>在给定数据的子集上挖掘，使用小的支持度和完整性验证方法  </p>
<p><strong>动态项集计数：</strong>在添加一个新的候选集之前，统计一下是不是他的所有子集都是频繁的。  </p>
<ul>
<li><p>Apriori算法优化(1)：只扫描数据库两次：  </p>
<pre><code>第一遍扫描：划分数据库，并找出局部频繁模式
第二遍扫描：求出全局频繁模式</code></pre></li>
<li><p>Apriori算法优化(2)：基于散列：  </p>
<pre><code>散列项集到对应的桶中，一个hash桶的计数小于阈值的k-itemset不可能是频繁的。</code></pre></li>
<li><p>Apriori算法优化(3):抽样频繁模式  </p>
<pre><code>选取一个样本挖掘。扫描一次数据库验证在样本中发现的频繁模式
再次扫描数据库，找出遗漏的频繁模式。</code></pre></li>
<li><p>Apriori算法优化(4):DIC<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/5AC8EC8A45DC428EB09C692E3316EC55/15884" alt="">  </p>
</li>
</ul>
<h3 id="FP-Growth–分治策略，无需产生候选频繁项集。"><a href="#FP-Growth–分治策略，无需产生候选频繁项集。" class="headerlink" title="FP Growth–分治策略，无需产生候选频繁项集。"></a>FP Growth–分治策略，无需产生候选频繁项集。</h3><p>&emsp;&emsp;&emsp;&emsp;&emsp;FP树是事务的压缩表示，每个事务都映射到FP树中的一条路径。<br>具体过程看机器学习FP树部分。 </p>
<p>&emsp;&emsp;&emsp;&emsp;&emsp;过程： </p>
<pre><code>1.对于每个频繁项，构造它的条件模式基  
2.然后构造它的条件fp-树  
3.在新构造的条件fp树上重复这一过程  
4.直到结果条件F树为空，或者它只包含一条路径-单个路径将产生其子路径的所有组合，每个子路径是一个频繁模式    </code></pre><p>&emsp;&emsp;&emsp;&emsp;&emsp;优点：<br>&emsp;&emsp;&emsp;&emsp;&emsp;1.<strong>完全性</strong>：保留频繁模式挖掘的完整信息，不截断任何事务的长模式<br>&emsp;&emsp;&emsp;&emsp;&emsp;2.<strong>紧密性</strong>：不频繁的项没有了，越是频繁出现，越可能被共享。不比原来的数据库大<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;FP算法对于挖掘长的和短的频繁模式都是有效的，可伸缩的。可比Apriori快一个量级。  </p>
<blockquote>
<p>为什么FP-growth是赢家？<br>分治：根据已经得到的频繁模式划分任务和数据库,导致较小范围的数据库的聚焦的搜索  </p>
</blockquote>
<p>没有候选产生，测试  </p>
<blockquote>
</blockquote>
<p>压缩了数据库–树结构  </p>
<blockquote>
</blockquote>
<p>不重复扫描整个数据库<br>没有模式搜索和匹配   </p>
<p><strong>强关联规则不一定有趣：</strong><br>&emsp;&emsp;&emsp;&emsp;<strong>提升度：</strong><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/A481502AB8DC417FA42832CF43F17D61/15941" alt=""><br>&emsp;&emsp;&emsp;&emsp;小于1则负相关，大于1则正相关，等于1则是独立的，没关系   </p>
<p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/DC684D54DA994314B8D34369878C3A60/15920" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/9D6A1CFA4A9245C78FC16EA0A71DDE45/15893" alt=""><br><img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/B0D391663AA24BFBA88FEE2F8E51141E/16607" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/3E80469F1B6B4FAFAF8DA4842FF65B1A/16609" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/FFAB5D29E9744BDDAC39EBB8FEC68A7E/16611" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/371759E6297449259518ED73CB1955B7/16613" alt="">  </p>
<hr>
<hr>
<h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><blockquote>
<p>分类：根据训练数据集和类标号属性，构建模型来分类现有数据，目标是分类新数据。 </p>
</blockquote>
<pre><code>鲁棒性：对噪声数据或者有空缺的数据，正确预测的能力
可伸缩性：对大量数据，有效的构建模型的能力
可解释性：学习模型提供的理解和洞察的层次  </code></pre><br>
### 决策树：由对象的若干属性，属性值和有关决策组成的一棵树。 


<h3 id="ID3算法"><a href="#ID3算法" class="headerlink" title="ID3算法:"></a>ID3算法:</h3><p>&emsp;&emsp;分之前的信息量：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/DAED1BB459864AB588B021487C130546/15942" alt="">  </p>
<p>&emsp;&emsp;分完以后的信息量：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/02DA6D8A9B6F4C5DB831AA74E6794F60/15935" alt="">  </p>
<p>&emsp;&emsp;信息增益：  </p>
<p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/7896DCE27568409E96E4893E05B2779C/15950" alt="">  </p>
<h3 id="C4-5算法"><a href="#C4-5算法" class="headerlink" title="C4.5算法:"></a>C4.5算法:</h3><p>&emsp;&emsp;增益率：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/CF5AB43A97D54F2E8506F4A091DB792D/15934" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/41CF519812444144854C3FA630733575/16036" alt=""><br><br><br><br><br><br></p>
<h3 id="CART算法："><a href="#CART算法：" class="headerlink" title="CART算法："></a>CART算法：</h3><blockquote>
<p>基尼指数：对每一个属性，进行一个二元划分。  </p>
</blockquote>
<p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/CEB629A3C5D94897B2182FBFAA4A674D/15957" alt=""><br>&emsp;&emsp;基尼指数考虑每个属性的二元划分：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/7DEFB187325B4740AF5BB91149A745DD/15932" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/BEE27E46DBE64589861D3681568B4312/16039" alt=""><br><br><br><br><br><br><br>用IF-THEN从树中生成分类规则：<br><img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/2C62BBC2630849B494FE3A5239C53CC0/15951" alt="">  </p>
<p>在分类中避免过度适应：两种方法避免过度适应—<strong>先剪枝后剪枝。</strong><br><br><br><br></p>
<blockquote>
<p>快速的，可伸缩的SLIQ算法：把训练样本集划分为若干子集，使每一个子样本集都能放入内存，然后对每个子样本分别构造一颗决策树，再把这些决策树综合，得到最终决策树。 </p>
</blockquote>
<br>
<br>
<br>

<h2 id="朴素贝叶斯："><a href="#朴素贝叶斯：" class="headerlink" title="朴素贝叶斯："></a>朴素贝叶斯：</h2><p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/B4D1025017174DD69014437F83E77215/15876" alt=""><br><strong>拉普拉斯校准：</strong><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/AB8F4CA7BE8649C2868B5AAD7DCA3881/15880" alt=""><br><strong>朴素贝叶斯优缺点：</strong>  </p>
<ul>
<li>优点：容易实现，大多数情况下能得到好的结果。  </li>
<li>缺点：假设类别互相条件独立导致一定程度的失真。实际中属性之间存在依赖。 <br> 
<br> 
<br> 
评估分类器性能的度量：
</li>
</ul>
<hr>
<pre><code>真正例：被分类到正确分类的正元组
真负例：被分类器正确分类的负元组
假正例：被错误的标记为正元组的负元组
假负例：被错误的标记为负元组的正元组</code></pre><p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;准确率：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/2864E8B02794410EB7A862E94604828D/15965" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;错误率：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/AEFA91E4A6874C0A99A45F252855D8F3/15962" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;召回率：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/44551A60324B4C3CBB9456783AFB9185/15963" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;精度：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/44D40E7565044FB897F827CCE0165D8E/15967" alt=""><br><strong>分类的准确性：</strong><br><strong>保持(holdout)：</strong>  </p>
<blockquote>
<p>训练集2/3，测试集(1/3)</p>
</blockquote>
<p><strong>K次交叉验证：</strong>  </p>
<blockquote>
<p>将数据集划分为K个子集，用K-1个做训练集，1个子集做测试集。  </p>
</blockquote>
<br> 
<br> 
<br> 
组合分类器的方法：
---  
**优点：**
>基分类器之间几乎不相关，但是基分类器要优于随机猜测。往往比成员分类器更准确：只有超过一半的基分类器出错时，组合分类器才会误分。当模型之间存在显著差异时，组合分类器产生更好的结果。可以并行。  


<p><strong>装袋Bagging：</strong>每次从数据集中抽取随机抽取n个样本，使用某个弱学习算法，使用多次，，得出预测函数序列进行投票。  </p>
<blockquote>
<p>要求不稳定（数据集小的变动能使结果产生显著变动）的分类方法：神经网络和决策树。</p>
</blockquote>
<p><strong>提升Boosting：</strong>把准确率不高的学习算法提升为准确率很高的学习算法。也要求”不稳定“的算法。  </p>
<blockquote>
<p>过程：每个样本都赋予一个权重，T次迭代，每次迭代后，对分类错误的样本加大权重，使得下一次的迭代更加关注这些样本。</p>
</blockquote>
<p><strong>区别：</strong>  </p>
<pre><code>Bagging：随机选择，各轮训练集相互独立，预测函数没有权重，可并行生成
Boosting：各轮选择集并不独立，它的选择与前轮的学习结果有关，有权重，只能顺序生产。</code></pre><br> 

<hr>
<hr>
<h2 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h2><blockquote>
<p> 聚类：把给定数据对象集划分为多个组或簇的过程，根据数据的特征找出数据间的相似性。  </p>
</blockquote>
<blockquote>
<p>无监督学习：没有预定义的类别，需要自动发现</p>
</blockquote>
<hr>
<p><strong>1.基于划分的聚类算法：</strong>  </p>
<blockquote>
<p>给定要划分的数目k，划分方法创建一个初始的基于形心的划分，然后采用迭代重定位技术，尝试通过对象在组间移动来改进划分    </p>
</blockquote>
<p><strong>K-Means算法</strong><br>&emsp;&emsp;&emsp;&emsp;算法流程：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;任选k个对象作为初始聚簇中心<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;将各个对象分配到距离最近的聚簇<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;重新计算各聚簇的中心<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;若有变化则返回2，知道无变化  </p>
<p>&emsp;&emsp;&emsp;&emsp;优缺点：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;描述容易，实现简单，快速<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;簇的个数难以确定<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;对初始值的选择很敏感，对噪音和异常数据敏感<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;容易陷入局部最优值<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;不能发现非凸形状的簇<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;仅当mean有定义才可用<br><strong>K-Medoids算法</strong><br>&emsp;&emsp;&emsp;&emsp;算法流程：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;选取簇中心点的准则函数是 : 当前簇中所有其他点到该中心点的距离之和最小，需要遍历簇中所有点<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;任意选取 k 个点作为 medoids<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;按照与medoids最近的原则，将剩余点分配到当前最佳的medoids代表的类中<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;在每一类中，计算每个成员点对应的准则函数，选取准则函数最小时对应的点作为新的   &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;medoids  </p>
<p><strong>CLARA算法：</strong>不考虑整个数据集，取一个具有代表性的样本来进行PAM  </p>
<blockquote>
<p>PAM算法：对小数据集很有效，但是对大数据集伸缩性不好<br>首先随机选择k个对象作为中心，把每个对象分配给离它最近的中心。<br>            然后随机地选择一个非中心对象替换中心对象，计算分配后的距离改进量<br>            如果总的损失减少，则交换中心对象和非中心对象；<br>            如果总的损失增加，则不进行交换  </p>
</blockquote>
<p><strong>CLARANS算法：</strong>  </p>
<ul>
<li>for i = 1 to v （选样的次数），重复执行下列步骤( (2) ～ (4) ) ；</li>
<li>随机地从整个数据库中抽取一个 N (例如：(40 + 2 k))个对象的样本，调用PAM 方法从样本中找出样本的k 个最优的中心点。</li>
<li>将这 k个中心点应用到整个数据库上，对于每一个非代表对象Oj，判断它与从样本中选出的哪个代表对象距离最近。</li>
<li>计算（3）中得到的聚类的总代价。若该值小于当前的最小值,用该值替换当前的最小值,保留在这次选样中得到的k 个代表对     象作为到目前为止得到的最好的代表对象的集合。</li>
<li>返回到步骤（1） ，开始下一个循环。  <h3 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h3>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/C6E6429852D846899D9287C17CB6C28B/15899" alt="">  </li>
</ul>
<hr>
<h3 id="层次聚类算法"><a href="#层次聚类算法" class="headerlink" title="层次聚类算法"></a>层次聚类算法</h3><blockquote>
<p>将数据对象组成一颗聚类的树不需要类别数k，一旦开始合并与分裂，就不能修正，可伸缩性不好，时间复杂度至少是O（n2）  </p>
</blockquote>
<p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/303D83FA6E0641D79B72FEFDCB2E0D3D/15906" alt=""><br><strong>类间距离计算方法：</strong><br>&emsp;&emsp;1.最小距离法：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/7A4553EC51B149259C2BDCE7CB244580/15946" alt=""><br>&emsp;&emsp;2.最大距离法:<br>&emsp;&emsp;3.重心法：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/C502EC699474400FBD1DF0C188E93FB0/15937" alt=""><br>&emsp;&emsp;4.类间平均距离法：类间所有样本点的平均距离<br><br><br><strong>BIRCH算法：</strong></p>
<blockquote>
<p>目标：为了使I/O时间尽可能小—- 1.首先构建CF树预聚类，2.然后对叶子结点进行聚类  </p>
</blockquote>
<p> CF树存储了：<br><img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/809C2B3020B04F00B168FC2E03E32948/15954" alt=""><br><img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/4390395E54794A57B2C05158AA9978B8/15923" alt="">  </p>
<p>CF树高度平衡，非叶子结点存储了其子女的CF总和，汇总了关于其子女的聚类信息。<strong>分支因子</strong>(非叶子结点子女的最大个数)和<strong>阈值T</strong>（叶子结点的最大直径），影响CF树的大小。    </p>
<p>BIRCH的<strong>优点</strong>：  </p>
<ul>
<li>支持增量聚类  </li>
<li>线性可伸缩性，计算复杂度：O（n）  </li>
<li>较好的聚类质量<br>&emsp;&emsp;缺点：<br>&emsp;&emsp;&emsp;1.只能处理数值数据<br>&emsp;&emsp;&emsp;2.对数据输入次序敏感<br>&emsp;&emsp;&emsp;3.CF树结点不总是对应于用户考虑的自然簇<br>&emsp;&emsp;&emsp;4.簇非球形时效果不好<br><img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/D3C580B50B0F40719C495EFFAE7DC478/16085" alt=""><br>改进的层次聚类方法：集中于<strong>层次聚类和迭代重定位方法的集成</strong>。</li>
</ul>
<hr>
<h3 id="基于密度的方法："><a href="#基于密度的方法：" class="headerlink" title="基于密度的方法："></a>基于密度的方法：</h3><p><strong>DBSCAN:</strong></p>
<pre><code>直接密度可达：点p在点q的最小半径内
密度可达：点q有一个直接密度可达的点t，然后点p在点t的最小半径内。
密度相连：对于点q和点p都是点o密度可达的点，那么点q和点p是密度相连的。  </code></pre><p>&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/59EE3B9EC3D244BAA93BC432131CCD85/16094" alt=""></p>
<blockquote>
<p>缺点：1.对用户定义的参数是敏感的，设置的细微不同可能导致差别很大的聚类2.全局密度参数不能刻画内在的聚类结构  </p>
</blockquote>
<p><strong>OPTICS：</strong><br>为了同时构建不同的聚类，应当以特定的顺序来处理对象。<strong>优先选择最小的半径密度可达的对象</strong>，以便高密度的聚类能被首先完成  </p>
<p>每个对象存储两个值：<br>&emsp;&emsp;1.对象p核心距离是使得p成为核心对象的最小的半径，如果p不是核心对象，p的核心距离没有定义<br>&emsp;&emsp;2.对象q关于另一个对象p的可达距离。对象q到对象p的可达距离是指p的核心距离和p与q之间欧几里得距离之间的较大值。如果p不是核心对象，p和q之间的可达距离没有意义。  </p>
<p>  一个点有多个可达距离，选取最小的距离，因为最小的距离就是与该点距离最近的一个簇的距离。  </p>
<hr>
<h3 id="确定数据集中的簇数："><a href="#确定数据集中的簇数：" class="headerlink" title="确定数据集中的簇数："></a>确定数据集中的簇数：</h3><p><img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/CDD728192F664A82BBE5DEDFA135F118/15929" alt=""><br> <strong>测定聚类质量的外在方法：</strong><br>&emsp;&emsp;簇的<strong>同质性</strong>：越纯越好  </p>
<p>&emsp;&emsp;簇的<strong>完全性</strong>：两个对象属于相同的类别，要被分配到相同的簇  </p>
<p>&emsp;&emsp;碎布袋：把一个异种对象放入一个纯的簇中比放入碎步袋中受更大处罚  </p>
<p>&emsp;&emsp;小簇保持性：小类分裂比大类分裂更有害  </p>
<p>&emsp;&emsp;精度和召回率。<br><strong>测定聚类质量的内在方法：</strong><br>&emsp;&emsp;簇的分离情况和紧凑情况<br>&emsp;&emsp;绘制方差和k的曲线，找到明显的拐点。</p>
<br>
<br>
----------

<hr>
<h2 id="离群点监测"><a href="#离群点监测" class="headerlink" title="离群点监测"></a>离群点监测</h2><blockquote>
<p>离群点是在数据集中偏离大部分数据的数据。  </p>
</blockquote>
<p><strong>全局离群点</strong>：在给定的数据集中，显著偏离的对象<br><strong>情境离群点</strong><br><strong>集体离群点</strong>：一个对象可能相对于所有对象看上去离群，但它相对于它的局部近邻不是离群的。<br><br><br><strong>参数方法：</strong>用一个参数模型来描述数据的分布。<br>&emsp;&emsp;&emsp;&emsp;一元离群点检测：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<strong>正态分布：</strong><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/B81B2EDFF8DA4E078D1E0A9A738207E1/15966" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;在这个区域之外的都是离群点。 </p>
<p>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<strong>四分位数：</strong><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/8A96B3CC336B471D9B9FA039EEE76D5C/15964" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;值高/低于四分位数 1.5 X IQR的都是离群点  </p>
<p>&emsp;&emsp;&emsp;&emsp;<strong>多元数据离群点监测：</strong><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<strong>卡方分布X2统计量：</strong><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/E89D8A891A434611AB302F0215AF35A9/15952" alt=""><br><img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/2CFA7E1292DE4757A937D088B397D93C/15918" alt="">  </p>
<p><strong>非参数方法：</strong><br>直方图：缺点：很难选择一个合适的箱尺寸。<br>      构造直方图<br>      检测离群点<br><strong>基于统计的离群点检测优缺点：</strong> </p>
<blockquote>
<p>优点:具有坚实的基础，当存在充分的数据和所用的检验类型的知识时，这些检验可能非常有效    </p>
</blockquote>
<blockquote>
<p>缺点：<br>大部分针对单元属性的，多元属性比较少<br>许多情况下，数据分布是未知的<br>对于高维数据，很难估计真实的分布<br>不适合混合类型数据。 </p>
</blockquote>
<p><strong>基于距离的离群点检测：</strong><br>    1.例子：<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/B676926FC47B47C5B6856E8B12C46830/15903" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/1CBB46620D6445A3AC79070783678F16/15896" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/FE043BF0777A43CBB2E4DF1710BA65F2/15905" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/DF846D8DC1844B138B48DE5743AD8660/15890" alt=""></p>
<p>基于距离检测的优缺点：</p>
<blockquote>
<p>优点：简单<br> 缺点：对参数k的选择很敏感。不能处理不同密度区域的数据集，使用全局阈值，无法考虑密度变化。需要一定的先验知识，点的离群程度是以二元方式报告的。  </p>
</blockquote>
<p><strong>基于密度的KNN方法：LOF</strong></p>
<p><img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/45737E0F4FA14552B3AB0D25C2686DFA/15873" alt=""><br><img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/9263B01EBCCC414C8BEF448CABAA0FA4/15916" alt=""><br>先算出每个点的k-distance —第k个邻域点的距离<br>然后对每个点，找到所有邻域点Oi的k-distance，以Oi为中心看到当前点P的可达距离是多少，然后如下图，算出每个点的LOF<br><img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/B239CF38CE10436DA3DF157FDCBB7587/15878" alt=""><br><strong>基于聚类的离群点检测：</strong> </p>
<p> 第一阶段对数据进行聚类<br> 第二阶段计算对象或簇的离群因子，并按离群因子进行排序，最终确定离群簇，也确定离群对象<br> 对象离群因子定义：<br> 簇的摘要信息：<br><img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/E2D932A837B64D93B5656EF08E001F49/15948" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/9CFD73C02919424E988ECA2491000A8B/16177" alt="">  </p>
<p><strong>离群因子定义：</strong></p>
<p>离群因子定义1:<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/17A378FAAFC345058C71A76FD04F1A13/15914" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/ABEE369567384354B69B55395DFF3CB1/15898" alt=""><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/695AC4C2D33F45AAB4D2957AA239C701/15887" alt=""><br>离群因子定义2:<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/1206BE66DC594BE387300E4F8E7827CD/15908" alt=""><br>离群因子定义3:<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/667ED89D5F3048ABBB084E0E3434EBB8/15897" alt=""><br><img src="https://note.youdao.com/yws/public/resource/5293e59d1c0da67574e2ddc6d90dbab7/xmlnote/6ED50E244D16439DBBB17C5944849E92/15874" alt=""><br>高维空间离群点检测：<br>&emsp;&emsp;1.对传统的低维空间方法的延伸<br>&emsp;&emsp;2.降维PCA<br>&emsp;&emsp;3.发现子空间中的离群点<br>&emsp;&emsp;4.对高维离群点建模  </p>

  </article>
</div>


    




</div>

<div class="footer-wrapper container">
  <footer class="footer clearfix">
    <div class="clearfix">
    <a href="http://guoer03.xyz" class="footer-logo">
      <i class="fa fa-github"></i>
    </a>
    <ul class="footer-social-link">
      <li>© 2020 Arthur Ming</li>
      <li><a href="http://guoer03.xyz">Home</a></li>
      
    </ul>
    <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
 
    <span id="busuanzi_container_site_pv">总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <div class="footer-theme-info">
      MingHai ❤ Love My girl gl
    </div>
    </div>
    
  </footer>
</div>




<script src="/js/main.js"></script>

</body>
</html>
